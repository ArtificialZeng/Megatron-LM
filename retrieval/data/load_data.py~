# lawrence mcafee

# ~~~~~~~~ import ~~~~~~~~
import glob
import h5py
import numpy as np
import socket

from lutil import pax

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
def get_data_paths(args):

    hostname = socket.gethostname()
    # pax({"hostname": hostname})

    # ~~~~~~~~ feat paths [ hdf5 ] ~~~~~~~~
    if hostname.startswith("luna-"):
        if args.data_ty == "rand":
            if 0:
                return np.random.rand(args.ntrain, 1024).astype("f4")
            else:
                from sklearn.datasets import make_blobs
                data, labels, centers = make_blobs(
                    n_samples = args.ntrain,
                    n_features = 1024,
                    centers = 32,
                    return_centers = True,
                )
                pax({
                    "data" : data,
                    "labels" : labels,
                    "centers" : centers,
                })
                return data
        elif args.data_ty == "corpus":
            feat_paths = glob.glob("/lustre/fsw/adlr/adlr-nlp/lmcafee/data/retrieval/sampled_pretraining/*.feat.hdf5")
        else:
            raise Exception("specialize for '%s'." % args.data_ty)

    elif hostname.startswith("rno"):
        # feat_paths = glob.glob(args.base_dir + "/enwiki-feat-16/*.hdf5")
        # feat_paths = glob.glob(args.base_dir + "/enwiki-feat-16-split/*.hdf5")
        # feat_paths = glob.glob(args.base_dir + "/enwiki-feat-1024/0000.hdf5")
        # feat_paths = glob.glob(args.base_dir + "/v2/data0/*feat.hdf5")
        if args.data_ty == "wiki":
            feat_paths = glob.glob(args.base_dir + "/v2/data1/feat/*feat.hdf5") # matches banned doc_ids
        elif args.data_ty == "corpus":
            # feat_paths = glob.glob("/gpfs/fs1/projects/gpu_adlr/datasets/boxinw/pretrained_data/pretrain*feat.hdf5")
            feat_paths = glob.glob("/gpfs/fs1/projects/gpu_adlr/datasets/boxinw/processed_data/chunks/sampled_pretraining/*.feat.hdf5")
            # feat_paths = glob.glob("/gpfs/fs1/projects/gpu_adlr/datasets/lmcafee/../boxinw/processed_data/chunks/sampled_pretraining/*.feat.hdf5")
        else:
            raise Exception("specialize for '%s'." % args.data_ty)

    else:
        raise Exception("specialize for hostname '%s'." % hostname)

    feat_paths.sort()

    args.data_paths = feat_paths

    # >>>
    # n = 0
    # for i, p in enumerate(feat_paths):
    #     if i % 20 == 0:
    #         print("counting feat path %d / %d." % (i, len(feat_paths)))
    #     f = h5py.File(p, "r")
    #     n += len(f["feat"])
    # pax({
    #     "feat_paths" : feat_paths,
    #     "n" : n,
    # })
    # <<<

    # return feat_paths

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# def load_train_data(ntrain):
# def load_train_data(args):
# def load_data(args):
def load_data(args, data_paths):

    pax({"data_paths": data_paths})

    # ~~~~~~~~ load feats ~~~~~~~~
    train_data = np.zeros((args.ntrain, args.nfeats), 'float32')
    nloaded = 0
    for i, feat_path in enumerate(feat_paths):

        # >>>
        # if i == 10:
        #     break
        # <<<

        f = h5py.File(feat_path, "r")
        if 1:
            d = np.copy(f["feat"])
            i0 = nloaded
            i1 = min(len(train_data), i0 + len(d))
            d = d[:i1-i0]
            if np.isnan(d).any():
                np.nan_to_num(d, copy = False, nan = 0.0)
            try:
                train_data[i0:i1] = d
            except:
                pax({
                    "nloaded" : nloaded,
                    "train_data" : str(train_data.shape),
                    "d" : str(d.shape),
                })
        else:
            train_datas.append(f["feat"])
        f.close()

        nloaded += len(d)

        print(
            "load feat path %d / %d ... vecs %d." % (i, len(feat_paths), nloaded),
            flush = True,
        )

        if nloaded >= args.ntrain:
            break

    args.ntrain = min(args.ntrain, nloaded)
    train_data = train_data[:args.ntrain]

    # pax({
    #     # "train_datas" : [ a.shape for a in train_datas ],
    #     "train_data / shape" : str(train_data.shape),
    #     "train_data / dtype" : str(train_data.dtype),
    #     "args" : args,
    # })

    return train_data

# eof
